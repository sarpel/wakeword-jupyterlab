{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455d3c2a",
   "metadata": {},
   "source": [
    "# Wakeword Training - Colab & JupyterLab Uyumlu\n",
    "\n",
    "CUDA/GPU doğrulamalı, her 10 epoch checkpoint kaydeden, TorchMetrics ve TensorBoard entegrasyonlu eğitim defteri. Colab'da Drive'dan 7z ve npy içeriği kullanımı dahildir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b680da",
   "metadata": {},
   "source": [
    "## 1) Plan ve TODO Listesi (Sequential Thinking)\n",
    "Aşamalar: 1) ortam/paketler, 2) GPU doğrulama, 3) Colab-Drive montajı ve veri çıkarımı, 4) yol yapılandırması, 5) veri yükleyiciler, 6) model, 7) kayıp/optimizer/metrics, 8) TensorBoard, 9) eğitim (10 epoch checkpoint), 10) doğrulama, 11) checkpoint yükleme, 12) Colab TensorBoard, 13) GPU izleme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planı kod olarak yazdır\n",
    "plan = [\n",
    "    \"Ortam ve paket kurulumları\",\n",
    "    \"GPU doğrulama\",\n",
    "    \"Colab-Drive montajı ve veri çıkarımı (7z + npy)\",\n",
    "    \"Yol yapılandırması\",\n",
    "    \"Veri yükleyiciler\",\n",
    "    \"Model\",\n",
    "    \"Kayıp/Optimizer/Metrics (TorchMetrics)\",\n",
    "    \"TensorBoard\",\n",
    "    \"Eğitim (10 epoch'ta bir checkpoint)\",\n",
    "    \"Doğrulama/Test\",\n",
    "    \"Checkpoint yükleme ve devam\",\n",
    "    \"Colab TensorBoard\",\n",
    "    \"GPU izleme\"\n",
    "]\n",
    "for i, item in enumerate(plan, 1):\n",
    "    print(f\"{i}. {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb7b6b",
   "metadata": {},
   "source": [
    "## 2) Paket Kurulumu ve Sürüm Sabitleme (JupyterLab ve Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab ve lokal kurulum\n",
    "import sys, os, platform\n",
    "IN_COLAB = 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules\n",
    "\n",
    "# Temel paketler\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install torchmetrics>=1.4.0 tensorboard>=2.14.0 py7zr>=0.20.7 tqdm numpy<2.0\n",
    "\n",
    "# Colab'da gerekiyorsa CUDA destekli PyTorch kurulumu (çoğu zaman hazır gelir)\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        import torch\n",
    "        print('Colab Torch sürümü:', torch.__version__)\n",
    "    except Exception:\n",
    "        # Örnek: CUDA 12.1 için\n",
    "        !pip -q install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\n",
    "        import torch\n",
    "        print('Kurulan Torch sürümü:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd6241",
   "metadata": {},
   "source": [
    "## 3) CUDA/GPU Doğrulama ve İzleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA doğrulama ve nvidia-smi\n",
    "import subprocess, shlex, time, threading\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# Basit GPU monitor iş parçacığı\n",
    "gpu_monitor_stop = False\n",
    "\n",
    "def gpu_monitor(interval=10):\n",
    "    global gpu_monitor_stop\n",
    "    while not gpu_monitor_stop:\n",
    "        try:\n",
    "            cmd = 'nvidia-smi --query-gpu=timestamp,index,name,utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits'\n",
    "            out = subprocess.check_output(shlex.split(cmd)).decode().strip()\n",
    "            print('[GPU]', out)\n",
    "        except Exception as e:\n",
    "            print('[GPU monitor error]', e)\n",
    "            break\n",
    "        time.sleep(interval)\n",
    "\n",
    "mon_thread = threading.Thread(target=gpu_monitor, args=(30,), daemon=True)\n",
    "mon_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1258d4d",
   "metadata": {},
   "source": [
    "## 4) Google Colab: Drive Bağlantısı ve 7z/NPY İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive montajı ve dosya çıkarma yardımcıları\n",
    "import shutil, pathlib, py7zr\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# Örnek: Drive'da saklanan arşiv ve npy dizinleri\n",
    "DRIVE_BASE = '/content/drive/MyDrive/wakeword'\n",
    "ARCHIVES = [\n",
    "    # ('source_path_in_drive', 'target_dir_name_under_content')\n",
    "    (f'{DRIVE_BASE}/positive_dataset.7z', 'positive_dataset'),\n",
    "    (f'{DRIVE_BASE}/negative_dataset.7z', 'negative_dataset'),\n",
    "]\n",
    "NPY_SOURCES = [\n",
    "    (f'{DRIVE_BASE}/features_train_npy', '/content/features/train'),\n",
    "]\n",
    "\n",
    "runtime_base = '/content' if IN_COLAB else os.getcwd()\n",
    "\n",
    "# Arşivleri kopyala ve çıkar\n",
    "def extract_archives(archives):\n",
    "    for src, target_name in archives:\n",
    "        target_dir = os.path.join(runtime_base, target_name)\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        local_7z = os.path.join(runtime_base, os.path.basename(src))\n",
    "        if os.path.exists(src):\n",
    "            print('Kopyalanıyor:', src, '->', local_7z)\n",
    "            shutil.copy2(src, local_7z)\n",
    "            print('Çıkarılıyor:', local_7z, '->', target_dir)\n",
    "            with py7zr.SevenZipFile(local_7z, mode='r') as z:\n",
    "                z.extractall(path=target_dir)\n",
    "        else:\n",
    "            print('Bulunamadı (atlandı):', src)\n",
    "\n",
    "# NPY dizinlerini kopyala\n",
    "def copy_npy_dirs(pairs):\n",
    "    for src_dir, dst_dir in pairs:\n",
    "        if os.path.exists(src_dir):\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            print('NPY kopyalanıyor:', src_dir, '->', dst_dir)\n",
    "            # Recurse copy\n",
    "            for root, dirs, files in os.walk(src_dir):\n",
    "                rel = os.path.relpath(root, src_dir)\n",
    "                out_root = os.path.join(dst_dir, rel)\n",
    "                os.makedirs(out_root, exist_ok=True)\n",
    "                for f in files:\n",
    "                    if f.endswith('.npy'):\n",
    "                        shutil.copy2(os.path.join(root, f), os.path.join(out_root, f))\n",
    "        else:\n",
    "            print('NPY kaynak yok (atlandı):', src_dir)\n",
    "\n",
    "if IN_COLAB:\n",
    "    extract_archives(ARCHIVES)\n",
    "    copy_npy_dirs(NPY_SOURCES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7992009",
   "metadata": {},
   "source": [
    "## 5) Yol Yapılandırması (Local ve Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yol ve konfig\n",
    "from pathlib import Path\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "BASE = Path('/content') if IN_COLAB else Path(os.getcwd())\n",
    "DATA_POS = str(BASE / 'positive_dataset')\n",
    "DATA_NEG = str(BASE / 'negative_dataset')\n",
    "FEATURES_DIR = str(BASE / 'features' / 'train')\n",
    "CKPT_DIR = str(BASE / 'checkpoints'); Path(CKPT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "RUNS_DIR = str(BASE / 'runs'); Path(RUNS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('POS:', DATA_POS)\n",
    "print('NEG:', DATA_NEG)\n",
    "print('FEAT:', FEATURES_DIR)\n",
    "print('CKPT:', CKPT_DIR)\n",
    "print('RUNS:', RUNS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216124c2",
   "metadata": {},
   "source": [
    "## 6) Veri Yükleyicileri (Dataset/DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a834632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje dataset ve dataloader\n",
    "sys.path.append(os.getcwd())\n",
    "from training.enhanced_dataset import EnhancedAudioConfig, create_dataloaders\n",
    "\n",
    "audio_cfg = EnhancedAudioConfig(\n",
    "    use_precomputed_features=True,\n",
    "    features_dir=FEATURES_DIR,\n",
    ")\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    positive_dir=DATA_POS,\n",
    "    negative_dir=DATA_NEG,\n",
    "    features_dir=FEATURES_DIR,\n",
    "    batch_size=32,\n",
    "    config=audio_cfg,\n",
    ")\n",
    "print('Train/Val:', len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5a27b",
   "metadata": {},
   "source": [
    "## 7) Model Tanımı (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ModelCfg:\n",
    "    input_size = 40\n",
    "    hidden_size = 256\n",
    "    num_layers = 2\n",
    "    dropout = 0.6\n",
    "    num_classes = 2\n",
    "\n",
    "class WakeModel(nn.Module):\n",
    "    def __init__(self, cfg: ModelCfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout_cnn = nn.Dropout(0.3)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128 * (cfg.input_size // 8),\n",
    "            hidden_size=cfg.hidden_size,\n",
    "            num_layers=cfg.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=cfg.dropout if cfg.num_layers>1 else 0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.attn = nn.Linear(cfg.hidden_size*2, 1)\n",
    "        self.drop = nn.Dropout(cfg.dropout)\n",
    "        self.fc1 = nn.Linear(cfg.hidden_size*2, 128)\n",
    "        self.fc2 = nn.Linear(128, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout_cnn(x)\n",
    "        B,C,Hp,Wp = x.shape\n",
    "        x = x.permute(0,3,1,2).contiguous().view(B, Wp, C*Hp)\n",
    "        lstm_out,_ = self.lstm(x)\n",
    "        a = torch.softmax(self.attn(lstm_out), dim=1)\n",
    "        z = torch.sum(a*lstm_out, dim=1)\n",
    "        z = self.drop(z)\n",
    "        z = F.relu(self.fc1(z))\n",
    "        return self.fc2(z)\n",
    "\n",
    "model_cfg = ModelCfg()\n",
    "model = WakeModel(model_cfg).to(device)\n",
    "print('Model params:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559193a0",
   "metadata": {},
   "source": [
    "## 8) Kayıp, Optimizasyon ve TorchMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5)\n",
    "\n",
    "acc_tr = BinaryAccuracy().to(device)\n",
    "pre_tr = BinaryPrecision().to(device)\n",
    "rec_tr = BinaryRecall().to(device)\n",
    "f1_tr  = BinaryF1Score().to(device)\n",
    "\n",
    "acc_va = BinaryAccuracy().to(device)\n",
    "pre_va = BinaryPrecision().to(device)\n",
    "rec_va = BinaryRecall().to(device)\n",
    "f1_va  = BinaryF1Score().to(device)\n",
    "\n",
    "from datetime import datetime\n",
    "run_name = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "writer = SummaryWriter(log_dir=os.path.join(RUNS_DIR, f'colab-{run_name}'))\n",
    "print('TB dir:', writer.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd5859",
   "metadata": {},
   "source": [
    "## 9) TensorBoard Kurulumu ve Yazar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametreleri TB'a yaz\n",
    "writer.add_text('hparams', str({\n",
    "    'batch_size': 32,\n",
    "    'lr': 1e-4,\n",
    "    'scheduler': 'ReduceLROnPlateau(0.5, patience=5)',\n",
    "    'save_every': 10,\n",
    "}))\n",
    "\n",
    "# Opsiyonel: Model grafiği için dummy input\n",
    "# Not: giriş boyutunuz (B,C,T) = (1,40,?) ise aşağıdaki örnek çalışır hale getirilebilir\n",
    "# try:\n",
    "#     dummy = torch.randn(1, 40, 128).to(device)\n",
    "#     writer.add_graph(model, dummy)\n",
    "# except Exception as e:\n",
    "#     print('Graph eklenemedi:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3ade7",
   "metadata": {},
   "source": [
    "## 10) Eğitim Döngüsü (Checkpoint her 10 epoch + TensorBoard + Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ckpt_dir = Path(CKPT_DIR)\n",
    "last_ckpt = ckpt_dir / 'last_checkpoint.pth'\n",
    "best_ckpt = ckpt_dir / 'best_model.pth'\n",
    "\n",
    "start_epoch = 0\n",
    "best_val_f1 = -1.0\n",
    "\n",
    "# Eğitim yardımcıları\n",
    "def reset_train_metrics():\n",
    "    acc_tr.reset(); pre_tr.reset(); rec_tr.reset(); f1_tr.reset()\n",
    "\n",
    "def reset_val_metrics():\n",
    "    acc_va.reset(); pre_va.reset(); rec_va.reset(); f1_va.reset()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    reset_val_metrics()\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch['features'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total += loss.item()\n",
    "            probs = torch.softmax(logits, dim=1)[:,1]\n",
    "            acc_va.update(probs, y)\n",
    "            pre_va.update(probs, y)\n",
    "            rec_va.update(probs, y)\n",
    "            f1_va.update(probs, y)\n",
    "    n = max(1, len(val_loader))\n",
    "    return {\n",
    "        'loss': total / n,\n",
    "        'acc': acc_va.compute().item(),\n",
    "        'prec': pre_va.compute().item(),\n",
    "        'rec': rec_va.compute().item(),\n",
    "        'f1': f1_va.compute().item(),\n",
    "    }\n",
    "\n",
    "def save_ckpt(epoch, tag=None):\n",
    "    tag_suffix = f\"_epoch_{epoch:04d}\" if tag is None else f\"_{tag}\"\n",
    "    path = ckpt_dir / f\"checkpoint{tag_suffix}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'scheduler_state': scheduler.state_dict() if scheduler else None,\n",
    "        'best_val_f1': best_val_f1,\n",
    "    }, path)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'scheduler_state': scheduler.state_dict() if scheduler else None,\n",
    "        'best_val_f1': best_val_f1,\n",
    "    }, last_ckpt)\n",
    "    print('Saved:', path)\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    reset_train_metrics()\n",
    "    running = 0.0\n",
    "    for batch in train_loader:\n",
    "        x = batch['features'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "        probs = torch.softmax(logits, dim=1)[:,1]\n",
    "        acc_tr.update(probs, y)\n",
    "        pre_tr.update(probs, y)\n",
    "        rec_tr.update(probs, y)\n",
    "        f1_tr.update(probs, y)\n",
    "\n",
    "    tr_loss = running / max(1, len(train_loader))\n",
    "    tr_acc, tr_pre, tr_rec, tr_f1 = [m.item() for m in (acc_tr.compute(), pre_tr.compute(), rec_tr.compute(), f1_tr.compute())]\n",
    "\n",
    "    val_stats = evaluate()\n",
    "    if scheduler:\n",
    "        scheduler.step(val_stats['loss'])\n",
    "\n",
    "    # TB yaz\n",
    "    writer.add_scalar('Loss/train', tr_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_stats['loss'], epoch)\n",
    "    writer.add_scalar('Acc/train', tr_acc, epoch)\n",
    "    writer.add_scalar('Acc/val', val_stats['acc'], epoch)\n",
    "    writer.add_scalar('F1/train', tr_f1, epoch)\n",
    "    writer.add_scalar('F1/val', val_stats['f1'], epoch)\n",
    "    writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | tr_loss={tr_loss:.4f} val_loss={val_stats['loss']:.4f} tr_f1={tr_f1:.4f} val_f1={val_stats['f1']:.4f}\")\n",
    "\n",
    "    # En iyi model kaydı\n",
    "    if val_stats['f1'] > best_val_f1:\n",
    "        best_val_f1 = val_stats['f1']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict() if scheduler else None,\n",
    "            'best_val_f1': best_val_f1,\n",
    "        }, best_ckpt)\n",
    "        print('Best model updated')\n",
    "\n",
    "    # 10 epoch'ta bir checkpoint\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_ckpt(epoch+1)\n",
    "\n",
    "# Final\n",
    "save_ckpt(EPOCHS, tag='final')\n",
    "writer.close()\n",
    "\n",
    "gpu_monitor_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b552c17",
   "metadata": {},
   "source": [
    "## 11) Doğrulama/Test Döngüsü\n",
    "(Üstte evaluate() fonksiyonu tanımlandı.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2dbc7",
   "metadata": {},
   "source": [
    "## 12) Checkpoint Yükleme ve Eğitime Devam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek: checkpoint yükleme\n",
    "ckpt_path = str(Path(CKPT_DIR) / 'last_checkpoint.pth')\n",
    "if os.path.exists(ckpt_path):\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state['model_state'])\n",
    "    optimizer.load_state_dict(state['optimizer_state'])\n",
    "    if state.get('scheduler_state') and scheduler:\n",
    "        scheduler.load_state_dict(state['scheduler_state'])\n",
    "    print('Checkpoint yüklendi. Kaldığı yerden devam edebilirsiniz.')\n",
    "else:\n",
    "    print('Checkpoint bulunamadı. Yeni eğitim başlatın.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ac5b6",
   "metadata": {},
   "source": [
    "## 13) Colab: TensorBoard Çalıştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4096d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab içinde TB\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir $RUNS_DIR --host 0.0.0.0 --port 6006\n",
    "else:\n",
    "    print('Lokal JupyterLab kullanıyorsanız terminalde çalıştırın:')\n",
    "    print('tensorboard --logdir runs --host 127.0.0.1 --port 6006')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37329721",
   "metadata": {},
   "source": [
    "## 14) Çalıştırma Konfigürasyonu ve CLI Argümanları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4eb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit konfig sözlüğü\n",
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 50,\n",
    "    'save_every': 10,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "    'pos_dir': DATA_POS,\n",
    "    'neg_dir': DATA_NEG,\n",
    "    'features_dir': FEATURES_DIR,\n",
    "    'ckpt_dir': CKPT_DIR,\n",
    "    'runs_dir': RUNS_DIR,\n",
    "}\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc870f29",
   "metadata": {},
   "source": [
    "## 15) GPU Kullanımı Canlı İzleme İş Parçacığı\n",
    "(Yukarıda başlatıldı; eğitim sonunda durduruldu.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
