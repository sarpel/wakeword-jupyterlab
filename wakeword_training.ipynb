{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Wakeword Training ‚Äì Live Control & GPU Setup\n",
    "\n",
    "Bu defter, Gradio uygulamasƒ±ndaki eƒüitimle aynƒ± paket s√ºr√ºmleri ve CUDA ayarlarƒ±nƒ± kullanƒ±r. A≈üaƒüƒ±daki h√ºcreler ile eƒüitim oturumunu ba≈ülatabilir, duraklatabilir, devam ettirebilir, son kontrol noktasƒ±ndan (checkpoint) yeniden ba≈ülatabilir ve canlƒ± metrikleri g√∂r√ºnt√ºleyebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ve paket kontrol√º (Gradio ile aynƒ± ortam)\n",
    "import torch, numpy as np\n",
    "print({\n",
    "    'numpy': np.__version__,\n",
    "    'torch': torch.__version__,\n",
    "    'cuda_available': torch.cuda.is_available(),\n",
    "    'cuda_device': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eƒüitim kontrol API'si ‚Äì gradio_app.py ile ortak kullanƒ±lƒ±r\n",
    "import importlib, os\n",
    "import gradio_app as appmod\n",
    "\n",
    "# Uygulama tekil instance\n",
    "app = appmod.app  # WakewordTrainingApp instance\n",
    "trainer = app.trainer\n",
    "\n",
    "print('Device:', app.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Processing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eƒüitim ba≈ülat (auto-extend a√ßƒ±k: gradio_app.py tarafƒ±nda etkin)\n",
    "# Not: load_data‚Äôyƒ± Gradio‚Äôda yaptƒ±ysanƒ±z tekrar yapmanƒ±z gerekmez; doƒürudan start_training √ßaƒürƒ±sƒ± yapƒ±labilir.\n",
    "\n",
    "status = app.start_training(\n",
    "    epochs=10,\n",
    "    lr=1e-4,\n",
    "    batch_size=32,\n",
    "    dropout=0.6,\n",
    ")\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canlƒ± metrikleri g√∂r√ºnt√ºle\n",
    "status, fig, metrics = app.get_training_status()\n",
    "print(status)\n",
    "print(metrics)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duraklat / Devam ettir\n",
    "print(app.pause_training())\n",
    "# ... bir s√ºre bekleyip devam etmek i√ßin:\n",
    "print(app.resume_training())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint‚Äôten devam etme\n",
    "print(app.continue_from_checkpoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Data Loading Section\n",
    "def prepare_enhanced_datasets(wakeword_dir='positive_dataset',\n",
    "                             negative_dir='negative_dataset',\n",
    "                             background_dir='background_noise',\n",
    "                             hard_negative_dir='hard_negatives'):\n",
    "    \"\"\"\n",
    "    Prepare datasets with proper categorization\n",
    "\n",
    "    Directory structure expected:\n",
    "    - positive_dataset/: Your positive samples\n",
    "    - negative_dataset/: General negative samples\n",
    "    - hard_negatives/: Phonetically similar negatives (if separate)\n",
    "    - background_noise/: 66 hours of background recordings\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the training cell to use enhanced dataset\n",
    "def create_enhanced_dataloaders(data_splits, processor, batch_size=16):\n",
    "    \"\"\"Create DataLoaders with the enhanced dataset\"\"\"\n",
    "\n",
    "    # Unpack splits\n",
    "    wake_train, hard_train, rand_train, bg_train = data_splits['train']\n",
    "    wake_val, hard_val, rand_val, bg_val = data_splits['val']\n",
    "    wake_test, hard_test, rand_test, bg_test = data_splits['test']\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = EnhancedWakewordDataset(\n",
    "        wakeword_files=wake_train,\n",
    "        hard_negative_files=hard_train,\n",
    "        random_negative_files=rand_train,\n",
    "        background_files=bg_train,\n",
    "        processor=processor,\n",
    "        augment=True,\n",
    "        background_mix_prob=0.7,\n",
    "        snr_range=(0, 20)\n",
    "    )\n",
    "\n",
    "    val_dataset = EnhancedWakewordDataset(\n",
    "        wakeword_files=wake_val,\n",
    "        hard_negative_files=hard_val,\n",
    "        random_negative_files=rand_val,\n",
    "        background_files=bg_val,\n",
    "        processor=processor,\n",
    "        augment=False,\n",
    "        background_mix_prob=0.5,  # Less mixing for validation\n",
    "        snr_range=(5, 15)  # More conservative SNR for validation\n",
    "    )\n",
    "\n",
    "    test_dataset = EnhancedWakewordDataset(\n",
    "        wakeword_files=wake_test,\n",
    "        hard_negative_files=hard_test,\n",
    "        random_negative_files=rand_test,\n",
    "        background_files=bg_test,\n",
    "        processor=processor,\n",
    "        augment=False,\n",
    "        background_mix_prob=0.5,\n",
    "        snr_range=(5, 15)\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Usage in your notebook:\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare datasets\n",
    "    data_splits = prepare_enhanced_datasets()\n",
    "\n",
    "    # Create processor (assuming it's already defined)\n",
    "    processor = AudioProcessor()\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader, val_loader, test_loader = create_enhanced_dataloaders(\n",
    "        data_splits,\n",
    "        processor,\n",
    "        batch_size=TrainingConfig.BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    print(\"\\nüöÄ Ready for training with background noise integration!\")\n",
    "    print(f\"   Background noise mixing probability: 70% for training\")\n",
    "    print(f\"   SNR range: 0-20 dB for training, 5-15 dB for validation\")\n",
    "    print(f\"   Total training batches: {len(train_loader)}\")\n",
    "    print(f\"   Total validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    checkpoint = torch.load('best_wakeword_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úÖ Best model loaded (epoch {checkpoint['epoch'] + 1}, val_acc: {checkpoint['val_acc']:.2f}%)\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device).squeeze()\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"\\nüìä Test Set Performance:\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall: {recall:.4f}\")\n",
    "    print(f\"   F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Negative', 'Wakeword'],\n",
    "                yticklabels=['Negative', 'Wakeword'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Negative', 'Wakeword']))\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No trained model found. Please run the training cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wakeword(audio_file_path, model, processor, device, threshold=0.8):\n",
    "    \"\"\"Predict if audio contains wakeword\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Process audio file\n",
    "    mel_spec = processor.process_audio_file(audio_file_path, augment=False)\n",
    "\n",
    "    if mel_spec is None:\n",
    "        print(f\"Error processing audio file: {audio_file_path}\")\n",
    "        return False, 0.0\n",
    "\n",
    "    # Convert to tensor and add batch dimension\n",
    "    mel_tensor = torch.FloatTensor(mel_spec).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(mel_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        wakeword_prob = probabilities[0][1].item()\n",
    "\n",
    "    is_wakeword = wakeword_prob >= threshold\n",
    "\n",
    "    return is_wakeword, wakeword_prob\n",
    "\n",
    "# Test prediction function\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    print(\"\\nüéØ Wakeword Detection System Ready!\")\n",
    "    print(\"You can now use the predict_wakeword function for real-time detection.\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"is_wakeword, confidence = predict_wakeword('./test_files/3.wav', model, processor, device)\")\n",
    "    print(f\"Result: {{'wakeword_detected': is_wakeword, 'confidence': confidence:.2f}}\")\n",
    "\n",
    "    # Create a simple test function\n",
    "    def test_audio_file(file_path):\n",
    "        if os.path.exists(file_path):\n",
    "            is_wakeword, confidence = predict_wakeword(file_path, model, processor, device)\n",
    "            print(f\"\\nüìÅ Testing: {file_path}\")\n",
    "            print(f\"   Wakeword detected: {is_wakeword}\")\n",
    "            print(f\"   Confidence: {confidence:.2f}\")\n",
    "            print(f\"   Threshold: 0.80\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå File not found: {file_path}\")\n",
    "\n",
    "    # Direct test with ./test_files/1.wav\n",
    "    test_audio_file(\"./test_files/3.wav\")\n",
    "else:\n",
    "    print(\"‚ùå Model not trained yet. Please run training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complete model for deployment\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    # Create a complete deployment package\n",
    "    deployment_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_config': {\n",
    "            'HIDDEN_SIZE': ModelConfig.HIDDEN_SIZE,\n",
    "            'NUM_LAYERS': ModelConfig.NUM_LAYERS,\n",
    "            'DROPOUT': ModelConfig.DROPOUT,\n",
    "            'NUM_CLASSES': ModelConfig.NUM_CLASSES\n",
    "        },\n",
    "        'audio_config': {\n",
    "            'SAMPLE_RATE': AudioConfig.SAMPLE_RATE,\n",
    "            'DURATION': AudioConfig.DURATION,\n",
    "            'N_MELS': AudioConfig.N_MELS,\n",
    "            'N_FFT': AudioConfig.N_FFT,\n",
    "            'HOP_LENGTH': AudioConfig.HOP_LENGTH,\n",
    "            'FMIN': AudioConfig.FMIN,\n",
    "            'FMAX': AudioConfig.FMAX\n",
    "        },\n",
    "        'training_info': {\n",
    "            'best_val_accuracy': checkpoint.get('val_acc', 0),\n",
    "            'epoch': checkpoint.get('epoch', 0) + 1,\n",
    "            'device': str(device)\n",
    "        },\n",
    "        'classes': ['negative', 'wakeword']\n",
    "    }\n",
    "\n",
    "    # Save deployment package\n",
    "    torch.save(deployment_package, 'wakeword_deployment_model.pth')\n",
    "    print(\"‚úÖ Deployment model saved as 'wakeword_deployment_model.pth'\")\n",
    "\n",
    "    # Save model architecture for reference\n",
    "    with open('model_architecture.txt', 'w') as f:\n",
    "        f.write(\"Wakeword Detection Model Architecture\\n\")\n",
    "        f.write(\"================================\\n\\n\")\n",
    "        f.write(\"Model Type: CNN + LSTM\\n\")\n",
    "        f.write(f\"Input Shape: (1, {AudioConfig.N_MELS}, 31)\\n\")\n",
    "        f.write(f\"Hidden Size: {ModelConfig.HIDDEN_SIZE}\\n\")\n",
    "        f.write(f\"Number of Layers: {ModelConfig.NUM_LAYERS}\\n\")\n",
    "        f.write(f\"Dropout: {ModelConfig.DROPOUT}\\n\")\n",
    "        f.write(f\"Number of Classes: {ModelConfig.NUM_CLASSES}\\n\")\n",
    "        f.write(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
    "        f.write(f\"Device: {device}\\n\")\n",
    "\n",
    "    print(\"‚úÖ Model architecture saved as 'model_architecture.txt'\")\n",
    "\n",
    "    print(\"\\nüéâ Model deployment package ready!\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"   - wakeword_deployment_model.pth (complete model)\")\n",
    "    print(\"   - model_architecture.txt (model specs)\")\n",
    "    print(\"   - best_wakeword_model.pth (training checkpoint)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No trained model found to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Add your wakeword recordings to positive_dataset/\")\n",
    "print(f\"   2. Add negative samples to negative_dataset/\")\n",
    "print(f\"   3. Add background noise to background_noise/\")\n",
    "print(f\"   4. Run the training cells above\")\n",
    "print(f\"   5. Use the trained model for wakeword detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
