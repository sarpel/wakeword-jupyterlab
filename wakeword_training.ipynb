{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Wakeword Training – Live Control & GPU Setup\n",
    "\n",
    "Bu defter, Gradio uygulamasındaki eğitimle aynı paket sürümleri ve CUDA ayarlarını kullanır. Aşağıdaki hücreler ile eğitim oturumunu başlatabilir, duraklatabilir, devam ettirebilir, son kontrol noktasından (checkpoint) yeniden başlatabilir ve canlı metrikleri görüntüleyebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ve paket kontrolü (Gradio ile aynı ortam)\n",
    "import torch, numpy as np\n",
    "print({\n",
    "    'numpy': np.__version__,\n",
    "    'torch': torch.__version__,\n",
    "    'cuda_available': torch.cuda.is_available(),\n",
    "    'cuda_device': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim kontrol API'si – gradio_app.py ile ortak kullanılır\n",
    "import importlib, os\n",
    "import gradio_app as appmod\n",
    "\n",
    "# Uygulama tekil instance\n",
    "app = appmod.app  # WakewordTrainingApp instance\n",
    "trainer = app.trainer\n",
    "\n",
    "print('Device:', app.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Processing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim başlat (auto-extend açık: gradio_app.py tarafında etkin)\n",
    "# Not: load_data’yı Gradio’da yaptıysanız tekrar yapmanız gerekmez; doğrudan start_training çağrısı yapılabilir.\n",
    "\n",
    "status = app.start_training(\n",
    "    epochs=10,\n",
    "    lr=1e-4,\n",
    "    batch_size=32,\n",
    "    dropout=0.6,\n",
    ")\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canlı metrikleri görüntüle\n",
    "status, fig, metrics = app.get_training_status()\n",
    "print(status)\n",
    "print(metrics)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duraklat / Devam ettir\n",
    "print(app.pause_training())\n",
    "# ... bir süre bekleyip devam etmek için:\n",
    "print(app.resume_training())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint’ten devam etme\n",
    "print(app.continue_from_checkpoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Data Loading Section\n",
    "def prepare_enhanced_datasets(wakeword_dir='positive_dataset',\n",
    "                             negative_dir='negative_dataset',\n",
    "                             background_dir='background_noise',\n",
    "                             hard_negative_dir='hard_negatives'):\n",
    "    \"\"\"\n",
    "    Prepare datasets with proper categorization\n",
    "\n",
    "    Directory structure expected:\n",
    "    - positive_dataset/: Your positive samples\n",
    "    - negative_dataset/: General negative samples\n",
    "    - hard_negatives/: Phonetically similar negatives (if separate)\n",
    "    - background_noise/: 66 hours of background recordings\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the training cell to use enhanced dataset\n",
    "def create_enhanced_dataloaders(data_splits, processor, batch_size=16):\n",
    "    \"\"\"Create DataLoaders with the enhanced dataset\"\"\"\n",
    "\n",
    "    # Unpack splits\n",
    "    wake_train, hard_train, rand_train, bg_train = data_splits['train']\n",
    "    wake_val, hard_val, rand_val, bg_val = data_splits['val']\n",
    "    wake_test, hard_test, rand_test, bg_test = data_splits['test']\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = EnhancedWakewordDataset(\n",
    "        wakeword_files=wake_train,\n",
    "        hard_negative_files=hard_train,\n",
    "        random_negative_files=rand_train,\n",
    "        background_files=bg_train,\n",
    "        processor=processor,\n",
    "        augment=True,\n",
    "        background_mix_prob=0.7,\n",
    "        snr_range=(0, 20)\n",
    "    )\n",
    "\n",
    "    val_dataset = EnhancedWakewordDataset(\n",
    "        wakeword_files=wake_val,\n",
    "        hard_negative_files=hard_val,\n",
    "        random_negative_files=rand_val,\n",
    "        background_files=bg_val,\n",
    "        processor=processor,\n",
    "        augment=False,\n",
    "        background_mix_prob=0.5,  # Less mixing for validation\n",
    "        snr_range=(5, 15)  # More conservative SNR for validation\n",
    "    )\n",
    "\n",
    "    test_dataset = EnhancedWakewordDataset(\n",
    "        wakeword_files=wake_test,\n",
    "        hard_negative_files=hard_test,\n",
    "        random_negative_files=rand_test,\n",
    "        background_files=bg_test,\n",
    "        processor=processor,\n",
    "        augment=False,\n",
    "        background_mix_prob=0.5,\n",
    "        snr_range=(5, 15)\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Usage in your notebook:\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare datasets\n",
    "    data_splits = prepare_enhanced_datasets()\n",
    "\n",
    "    # Create processor (assuming it's already defined)\n",
    "    processor = AudioProcessor()\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader, val_loader, test_loader = create_enhanced_dataloaders(\n",
    "        data_splits,\n",
    "        processor,\n",
    "        batch_size=TrainingConfig.BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    print(\"\\n🚀 Ready for training with background noise integration!\")\n",
    "    print(f\"   Background noise mixing probability: 70% for training\")\n",
    "    print(f\"   SNR range: 0-20 dB for training, 5-15 dB for validation\")\n",
    "    print(f\"   Total training batches: {len(train_loader)}\")\n",
    "    print(f\"   Total validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    checkpoint = torch.load('best_wakeword_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"✅ Best model loaded (epoch {checkpoint['epoch'] + 1}, val_acc: {checkpoint['val_acc']:.2f}%)\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device).squeeze()\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"\\n📊 Test Set Performance:\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall: {recall:.4f}\")\n",
    "    print(f\"   F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Negative', 'Wakeword'],\n",
    "                yticklabels=['Negative', 'Wakeword'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\n📋 Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Negative', 'Wakeword']))\n",
    "\n",
    "else:\n",
    "    print(\"❌ No trained model found. Please run the training cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wakeword(audio_file_path, model, processor, device, threshold=0.8):\n",
    "    \"\"\"Predict if audio contains wakeword\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Process audio file\n",
    "    mel_spec = processor.process_audio_file(audio_file_path, augment=False)\n",
    "\n",
    "    if mel_spec is None:\n",
    "        print(f\"Error processing audio file: {audio_file_path}\")\n",
    "        return False, 0.0\n",
    "\n",
    "    # Convert to tensor and add batch dimension\n",
    "    mel_tensor = torch.FloatTensor(mel_spec).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(mel_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        wakeword_prob = probabilities[0][1].item()\n",
    "\n",
    "    is_wakeword = wakeword_prob >= threshold\n",
    "\n",
    "    return is_wakeword, wakeword_prob\n",
    "\n",
    "# Test prediction function\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    print(\"\\n🎯 Wakeword Detection System Ready!\")\n",
    "    print(\"You can now use the predict_wakeword function for real-time detection.\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"is_wakeword, confidence = predict_wakeword('./test_files/3.wav', model, processor, device)\")\n",
    "    print(f\"Result: {{'wakeword_detected': is_wakeword, 'confidence': confidence:.2f}}\")\n",
    "\n",
    "    # Create a simple test function\n",
    "    def test_audio_file(file_path):\n",
    "        if os.path.exists(file_path):\n",
    "            is_wakeword, confidence = predict_wakeword(file_path, model, processor, device)\n",
    "            print(f\"\\n📁 Testing: {file_path}\")\n",
    "            print(f\"   Wakeword detected: {is_wakeword}\")\n",
    "            print(f\"   Confidence: {confidence:.2f}\")\n",
    "            print(f\"   Threshold: 0.80\")\n",
    "        else:\n",
    "            print(f\"\\n❌ File not found: {file_path}\")\n",
    "\n",
    "    # Direct test with ./test_files/1.wav\n",
    "    test_audio_file(\"./test_files/3.wav\")\n",
    "else:\n",
    "    print(\"❌ Model not trained yet. Please run training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complete model for deployment\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    # Create a complete deployment package\n",
    "    deployment_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_config': {\n",
    "            'HIDDEN_SIZE': ModelConfig.HIDDEN_SIZE,\n",
    "            'NUM_LAYERS': ModelConfig.NUM_LAYERS,\n",
    "            'DROPOUT': ModelConfig.DROPOUT,\n",
    "            'NUM_CLASSES': ModelConfig.NUM_CLASSES\n",
    "        },\n",
    "        'audio_config': {\n",
    "            'SAMPLE_RATE': AudioConfig.SAMPLE_RATE,\n",
    "            'DURATION': AudioConfig.DURATION,\n",
    "            'N_MELS': AudioConfig.N_MELS,\n",
    "            'N_FFT': AudioConfig.N_FFT,\n",
    "            'HOP_LENGTH': AudioConfig.HOP_LENGTH,\n",
    "            'FMIN': AudioConfig.FMIN,\n",
    "            'FMAX': AudioConfig.FMAX\n",
    "        },\n",
    "        'training_info': {\n",
    "            'best_val_accuracy': checkpoint.get('val_acc', 0),\n",
    "            'epoch': checkpoint.get('epoch', 0) + 1,\n",
    "            'device': str(device)\n",
    "        },\n",
    "        'classes': ['negative', 'wakeword']\n",
    "    }\n",
    "\n",
    "    # Save deployment package\n",
    "    torch.save(deployment_package, 'wakeword_deployment_model.pth')\n",
    "    print(\"✅ Deployment model saved as 'wakeword_deployment_model.pth'\")\n",
    "\n",
    "    # Save model architecture for reference\n",
    "    with open('model_architecture.txt', 'w') as f:\n",
    "        f.write(\"Wakeword Detection Model Architecture\\n\")\n",
    "        f.write(\"================================\\n\\n\")\n",
    "        f.write(\"Model Type: CNN + LSTM\\n\")\n",
    "        f.write(f\"Input Shape: (1, {AudioConfig.N_MELS}, 31)\\n\")\n",
    "        f.write(f\"Hidden Size: {ModelConfig.HIDDEN_SIZE}\\n\")\n",
    "        f.write(f\"Number of Layers: {ModelConfig.NUM_LAYERS}\\n\")\n",
    "        f.write(f\"Dropout: {ModelConfig.DROPOUT}\\n\")\n",
    "        f.write(f\"Number of Classes: {ModelConfig.NUM_CLASSES}\\n\")\n",
    "        f.write(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
    "        f.write(f\"Device: {device}\\n\")\n",
    "\n",
    "    print(\"✅ Model architecture saved as 'model_architecture.txt'\")\n",
    "\n",
    "    print(\"\\n🎉 Model deployment package ready!\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"   - wakeword_deployment_model.pth (complete model)\")\n",
    "    print(\"   - model_architecture.txt (model specs)\")\n",
    "    print(\"   - best_wakeword_model.pth (training checkpoint)\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No trained model found to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🚀 Next Steps:\")\n",
    "print(f\"   1. Add your wakeword recordings to positive_dataset/\")\n",
    "print(f\"   2. Add negative samples to negative_dataset/\")\n",
    "print(f\"   3. Add background noise to background_noise/\")\n",
    "print(f\"   4. Run the training cells above\")\n",
    "print(f\"   5. Use the trained model for wakeword detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
