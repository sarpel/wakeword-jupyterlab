{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wakeword Training (CUDA GPU Only + TorchMetrics + TensorBoard)\n",
    "\n",
    "Bu notebook, mevcut eƒüitim pipeline'ƒ±nƒ±zƒ± **yalnƒ±zca GPU √ºzerinde** √ßalƒ±≈ütƒ±rƒ±r, her 10 epoch'ta bir checkpoint kaydeder, TorchMetrics ile metrikleri hesaplar ve TensorBoard ile canlƒ± olarak izlenebilir loglar √ºretir.\n",
    "\n",
    "**√ñnemli:** CPU eƒüitimi yasaklanmƒ±≈ütƒ±r. CUDA GPU zorunludur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch: 2.1.2+cu118\n",
      "CUDA kullanƒ±labilir: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Ti\n",
      "Kullanƒ±lan cihaz: cuda\n"
     ]
    }
   ],
   "source": [
    "# Ortam ve baƒüƒ±mlƒ±lƒ±k kontrol√º (CUDA GPU zorunlu)\n",
    "import sys, os\n",
    "import torch\n",
    "\n",
    "# CUDA kontrol√º - CPU eƒüitimi yasak\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA GPU gerekli. CPU eƒüitimi politikaya g√∂re devre dƒ±≈üƒ±.\")\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "print(f\"CUDA kullanƒ±labilir: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# CUDA optimizasyonlarƒ±\n",
    "torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")  # TF32 etkinle≈ütir\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "device = torch.device('cuda')  # GPU zorunlu\n",
    "print(f\"Kullanƒ±lan cihaz: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K√ºt√ºphaneler ve proje mod√ºlleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje mod√ºllerini i√ße aktar\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from training.enhanced_dataset import EnhancedWakewordDataset, EnhancedAudioConfig, create_dataloaders\n",
    "from training.feature_extractor import FeatureExtractor\n",
    "\n",
    "# TorchMetrics & TensorBoard (sklearn.metrics kullanarak gradio_app ile uyumlu)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration Classes (gradio_app ile aynƒ±)\n",
    "class AudioConfig:\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 1.7\n",
    "    N_MELS = 80\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    WIN_LENGTH = 2048\n",
    "    FMIN = 0\n",
    "    FMAX = 8000\n",
    "\n",
    "# Model Configuration\n",
    "class ModelConfig:\n",
    "    def __init__(self, input_size=128):\n",
    "        self.HIDDEN_SIZE = 256\n",
    "        self.NUM_LAYERS = 2\n",
    "        self.DROPOUT = 0.6\n",
    "        self.NUM_CLASSES = 2\n",
    "        self.INPUT_SIZE = input_size  # Mel spectrogram height (frequency bins)\n",
    "\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 0.0001\n",
    "    EPOCHS = 100\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Enhanced Wakeword Model (gradio_app'den uyarlanmƒ±≈ü)\n",
    "class EnhancedWakewordModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout_cnn = nn.Dropout(0.3)\n",
    "\n",
    "        # LSTM input size calculation\n",
    "        # After 3 conv layers with maxpool: input_size // 8\n",
    "        lstm_input_size = 128 * (self.config.INPUT_SIZE // 8)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=self.config.HIDDEN_SIZE,\n",
    "            num_layers=self.config.NUM_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=self.config.DROPOUT if self.config.NUM_LAYERS > 1 else 0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.attention = nn.Linear(self.config.HIDDEN_SIZE * 2, 1)\n",
    "        self.dropout_lstm = nn.Dropout(self.config.DROPOUT)\n",
    "        self.fc1 = nn.Linear(self.config.HIDDEN_SIZE * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, self.config.NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T) - mel spectrogram\n",
    "        x = x.unsqueeze(1)  # (B, 1, C, T)\n",
    "\n",
    "        # CNN feature extraction\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_cnn(x)  # (B, 128, H', W')\n",
    "\n",
    "        B, C, Hp, Wp = x.shape\n",
    "        # LSTM i√ßin zaman boyutu W', feature boyutu 128*H'\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (B, W', 128, H')\n",
    "        x = x.view(B, Wp, C * Hp)               # (B, W', 128*H')\n",
    "\n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)              # (B, W', 2*hidden)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn = torch.softmax(self.attention(lstm_out), dim=1)  # (B, W', 1)\n",
    "        attended = torch.sum(attn * lstm_out, dim=1)           # (B, 2*hidden)\n",
    "\n",
    "        # Classification head\n",
    "        out = self.dropout_lstm(attended)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader ve eƒüitim yapƒ±landƒ±rmasƒ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedAudioConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m val_split \u001b[38;5;241m=\u001b[39m TrainingConfig\u001b[38;5;241m.\u001b[39mVALIDATION_SPLIT\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Audio konfig√ºrasyonu\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m audio_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mEnhancedAudioConfig\u001b[49m(\n\u001b[0;32m     18\u001b[0m     use_precomputed_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m     features_dir\u001b[38;5;241m=\u001b[39mFEATURES_DIR,\n\u001b[0;32m     20\u001b[0m     use_rirs_augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# Basit tutmak i√ßin devre dƒ±≈üƒ±\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     rirs_dataset_path\u001b[38;5;241m=\u001b[39mRIRS_DIR,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# DataLoader'larƒ± olu≈ütur\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlar olu≈üturuluyor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EnhancedAudioConfig' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Mevcut dizin yapƒ±sƒ±nƒ± kullan\n",
    "POS_DIR = 'positive_dataset'      # Pozitif wakeword √∂rnekleri\n",
    "NEG_DIR = 'negative_dataset'      # Negatif √∂rnekler\n",
    "FEATURES_DIR = 'features/train'   # Hazƒ±r .npy feature'lar\n",
    "BACKGROUND_DIR = 'background_noise'  # Arka plan g√ºr√ºlt√ºs√º\n",
    "RIRS_DIR = 'datasets/mit_rirs/rir_data'  # RIR verileri\n",
    "\n",
    "# Hiperparametreler (gradio_app ile aynƒ±)\n",
    "batch_size = TrainingConfig.BATCH_SIZE\n",
    "lr = TrainingConfig.LEARNING_RATE\n",
    "epochs = 50  # Notebook i√ßin daha kƒ±sa\n",
    "val_split = TrainingConfig.VALIDATION_SPLIT\n",
    "\n",
    "# Audio konfig√ºrasyonu\n",
    "audio_cfg = EnhancedAudioConfig(\n",
    "    use_precomputed_features=True,\n",
    "    features_dir=FEATURES_DIR,\n",
    "    use_rirs_augmentation=False,  # Basit tutmak i√ßin devre dƒ±≈üƒ±\n",
    "    rirs_dataset_path=RIRS_DIR,\n",
    ")\n",
    "\n",
    "# DataLoader'larƒ± olu≈ütur\n",
    "print(\"DataLoader'lar olu≈üturuluyor...\")\n",
    "try:\n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        positive_dir=POS_DIR,\n",
    "        negative_dir=NEG_DIR,\n",
    "        features_dir=FEATURES_DIR,\n",
    "        rirs_dir=RIRS_DIR,\n",
    "        batch_size=batch_size,\n",
    "        config=audio_cfg,\n",
    "    )\n",
    "    print(f\"‚úÖ Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå DataLoader olu≈üturma hatasƒ±: {e}\")\n",
    "    print(\"Feature dosyalarƒ±nƒ±n varlƒ±ƒüƒ±nƒ± kontrol edin...\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, optimizer, TorchMetrics ve TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ve optimizasyon (CUDA GPU zorunlu)\n",
    "device = torch.device('cuda')  # GPU zorunlu\n",
    "\n",
    "# Veri √∂rneƒüinden giri≈ü kanal sayƒ±sƒ±nƒ± t√ºret\n",
    "sample_batch = next(iter(train_loader))\n",
    "derived_input_size = int(sample_batch['features'].shape[1])  # (B, C, T) -> C\n",
    "print(f\"Feature input size: {derived_input_size}\")\n",
    "\n",
    "# Model konfig√ºrasyonu\n",
    "model_cfg = ModelConfig(input_size=derived_input_size)\n",
    "\n",
    "# Model olu≈ütur\n",
    "model = EnhancedWakewordModel(model_cfg).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# TorchMetrics (sklearn.metrics kullanarak gradio_app ile uyumlu)\n",
    "# Metrikler eƒüitim sƒ±rasƒ±nda hesaplanacak\n",
    "\n",
    "# TensorBoard setup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "run_name = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = os.path.join('runs', f'wakeword-{run_name}')\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "print(f\"‚úÖ Model olu≈üturuldu: {sum(p.numel() for p in model.parameters()):,} parametre\")\n",
    "print(f\"‚úÖ TensorBoard log dizini: {log_dir}\")\n",
    "print(f\"‚úÖ Cihaz: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eƒüitim d√∂ng√ºs√º (10 epoch‚Äôta checkpoint + resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "ckpt_dir = Path('checkpoints')\n",
    "ckpt_dir.mkdir(exist_ok=True)\n",
    "last_ckpt_path = ckpt_dir / 'last_checkpoint.pth'\n",
    "best_ckpt_path = ckpt_dir / 'best_model.pth'\n",
    "\n",
    "start_epoch = 0\n",
    "best_val_f1 = -1.0\n",
    "\n",
    "# Resume logic\n",
    "if last_ckpt_path.exists():\n",
    "    state = torch.load(last_ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state['model_state'])\n",
    "    optimizer.load_state_dict(state['optimizer_state'])\n",
    "    start_epoch = state.get('epoch', 0) + 1\n",
    "    best_val_f1 = state.get('best_val_f1', -1.0)\n",
    "    print(f\"üìÅ Checkpoint'ten devam: epoch {start_epoch}, best_val_f1={best_val_f1:.4f}\")\n",
    "\n",
    "# Metrik sƒ±fƒ±rlama fonksiyonu (sklearn i√ßin gerekli deƒüil)\n",
    "def step_metrics_reset():\n",
    "    pass  # sklearn metrics i√ßin sƒ±fƒ±rlama gerekmez\n",
    "\n",
    "# Deƒüerlendirme fonksiyonu (sklearn.metrics kullanarak)\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            x = batch['features'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            preds = (probs > 0.5).long()  # 0.5 threshold ile binary classification\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    n = max(1, len(loader))\n",
    "\n",
    "    # sklearn ile metrikleri hesapla\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / n,\n",
    "        'acc': acc,\n",
    "        'prec': prec,\n",
    "        'rec': rec,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Checkpoint kaydetme\n",
    "def save_checkpoint(epoch, tag=None):\n",
    "    tag_suffix = f\"_epoch_{epoch:04d}\" if tag is None else f\"_{tag}\"\n",
    "    path = ckpt_dir / f\"checkpoint{tag_suffix}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'config': model_cfg.__dict__,\n",
    "    }, path)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'config': model_cfg.__dict__,\n",
    "    }, last_ckpt_path)\n",
    "    print(f\"üíæ Checkpoint kaydedildi: {path}\")\n",
    "\n",
    "# Eƒüitim d√∂ng√ºs√º\n",
    "print(\"üöÄ Eƒüitim ba≈ülatƒ±lƒ±yor...\")\n",
    "print(f\"   Epochs: {epochs}, Batch size: {batch_size}, Learning rate: {lr}\")\n",
    "print(f\"   Cihaz: {device}\")\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    model.train()\n",
    "    step_metrics_reset()\n",
    "    running_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for i, batch in enumerate(train_pbar):\n",
    "        x = batch['features'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        preds = (probs > 0.5).long()  # 0.5 threshold ile binary classification\n",
    "\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(y.cpu().numpy())\n",
    "\n",
    "        # Progress bar g√ºncelle\n",
    "        train_pbar.set_postfix({\n",
    "            'loss': f\"{running_loss/(i+1):.4f}\",\n",
    "        })\n",
    "\n",
    "    # Eƒüitim metrikleri (sklearn ile)\n",
    "    n_train = max(1, len(train_loader))\n",
    "    train_loss = running_loss / n_train\n",
    "    train_acc = accuracy_score(train_labels, train_preds)\n",
    "    train_prec = precision_score(train_labels, train_preds, average='binary', zero_division=0)\n",
    "    train_rec = recall_score(train_labels, train_preds, average='binary', zero_division=0)\n",
    "    train_f1 = f1_score(train_labels, train_preds, average='binary', zero_division=0)\n",
    "\n",
    "    # Validasyon\n",
    "    val_stats = evaluate(model, val_loader)\n",
    "\n",
    "    # TensorBoard logging\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_stats['loss'], epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_stats['acc'], epoch)\n",
    "    writer.add_scalar('F1/train', train_f1, epoch)\n",
    "    writer.add_scalar('F1/val', val_stats['f1'], epoch)\n",
    "    writer.add_scalar('Precision/train', train_prec, epoch)\n",
    "    writer.add_scalar('Precision/val', val_stats['prec'], epoch)\n",
    "    writer.add_scalar('Recall/train', train_rec, epoch)\n",
    "    writer.add_scalar('Recall/val', val_stats['rec'], epoch)\n",
    "\n",
    "    # Progress print\n",
    "    print(f\"Epoch {epoch+1:3d}/{epochs} | \"\n",
    "          f\"train_loss={train_loss:.4f} val_loss={val_stats['loss']:.4f} | \"\n",
    "          f\"train_f1={train_f1:.4f} val_f1={val_stats['f1']:.4f}\")\n",
    "\n",
    "    # Best model kaydet\n",
    "    if val_stats['f1'] > best_val_f1:\n",
    "        best_val_f1 = val_stats['f1']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'best_val_f1': best_val_f1,\n",
    "            'config': model_cfg.__dict__,\n",
    "        }, best_ckpt_path)\n",
    "        print(f\"üèÜ Best model g√ºncellendi: F1={best_val_f1:.4f}\")\n",
    "\n",
    "    # 10 epoch'ta bir checkpoint\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "\n",
    "# Final checkpoint\n",
    "save_checkpoint(epochs, tag='final')\n",
    "writer.close()\n",
    "print('‚úÖ Eƒüitim tamamlandƒ±!')\n",
    "print(f\"üìä Best validation F1: {best_val_f1:.4f}\")\n",
    "print(f\"üìÅ TensorBoard logs: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard ƒ∞zleme\n",
    "\n",
    "Eƒüitim metriklerini canlƒ± olarak izlemek i√ßin TensorBoard'ƒ± ba≈ülatƒ±n:\n",
    "\n",
    "### Terminal Komutu:\n",
    "```powershell\n",
    "# PowerShell'de (Windows)\n",
    "$env:LOGDIR=\"runs\"; tensorboard --logdir $env:LOGDIR --host 127.0.0.1 --port 6006\n",
    "```\n",
    "\n",
    "### Alternatif olarak VS Code terminalinde:\n",
    "```bash\n",
    "# Linux/Mac veya WSL\n",
    "LOGDIR=runs tensorboard --logdir $LOGDIR --host 127.0.0.1 --port 6006\n",
    "```\n",
    "\n",
    "### Tarayƒ±cƒ±da eri≈üim:\n",
    "TensorBoard ba≈üladƒ±ktan sonra: http://127.0.0.1:6006\n",
    "\n",
    "### ƒ∞zlenecek Metrikler:\n",
    "- **Loss**: Eƒüitim ve validasyon kaybƒ±\n",
    "- **Accuracy**: Doƒüruluk oranlarƒ±  \n",
    "- **F1-Score**: F1 skorlarƒ± (precision + recall harmonik ortalamasƒ±)\n",
    "- **Precision**: Kesinlik\n",
    "- **Recall**: Duyarlƒ±lƒ±k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eƒüitim sonrasƒ± model deƒüerlendirmesi\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    print(\"üéØ Eƒüitim tamamlandƒ±! Model deƒüerlendirmesi i√ßin gradio_app.py'yi kullanabilirsiniz.\")\n",
    "    print(\"üìÅ Kaydedilen dosyalar:\")\n",
    "    print(\"   - best_wakeword_model.pth (en iyi model)\")\n",
    "    print(\"   - checkpoints/last_checkpoint.pth (son checkpoint)\")\n",
    "    print(\"   - runs/ dizininde TensorBoard loglarƒ±\")\n",
    "else:\n",
    "    print(\"‚ùå Model dosyasƒ± bulunamadƒ±. Eƒüitimi tekrar kontrol edin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adƒ±mlar\n",
    "\n",
    "1. **TensorBoard ile Metrik ƒ∞zleme**: Eƒüitim metriklerini canlƒ± olarak izleyin\n",
    "2. **Model Deƒüerlendirmesi**: `gradio_app.py` ile model performansƒ±nƒ± test edin\n",
    "3. **Deployment**: En iyi modeli `wakeword_deployment_model.pth` olarak kaydedin\n",
    "4. **ƒ∞nce Ayar**: Gerekirse hiperparametreleri ayarlayƒ±p eƒüitimi tekrarlayƒ±n\n",
    "\n",
    "### Kullanƒ±lan Paket S√ºr√ºmleri (gradio_app.py ile aynƒ±):\n",
    "- **PyTorch**: 2.1.2+cu118 (CUDA 11.8)\n",
    "- **TorchAudio**: 2.1.2+cu118\n",
    "- **TorchVision**: 0.16.2+cu118\n",
    "- **Scikit-learn**: >=1.0.0 (metrikler i√ßin)\n",
    "- **TensorBoard**: >=2.14.0\n",
    "- **CUDA GPU**: Zorunlu (CPU eƒüitimi yasak)\n",
    "\n",
    "*Not: TorchMetrics yerine sklearn.metrics kullanƒ±lƒ±yor (gradio_app uyumluluƒüu i√ßin)*\n",
    "\n",
    "### Diz Yapƒ±sƒ±:\n",
    "```\n",
    "‚îú‚îÄ‚îÄ positive_dataset/     # Wakeword √∂rnekleri\n",
    "‚îú‚îÄ‚îÄ negative_dataset/     # Negatif √∂rnekler\n",
    "‚îú‚îÄ‚îÄ features/train/       # Hazƒ±r .npy feature'lar\n",
    "‚îú‚îÄ‚îÄ background_noise/     # Arka plan g√ºr√ºlt√ºs√º\n",
    "‚îú‚îÄ‚îÄ checkpoints/          # Checkpoint'lar\n",
    "‚îú‚îÄ‚îÄ runs/                 # TensorBoard loglarƒ±\n",
    "‚îî‚îÄ‚îÄ best_wakeword_model.pth  # En iyi model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation (Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation on validation set\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    checkpoint = torch.load('best_wakeword_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    print(f\"‚úÖ Best model loaded (epoch {checkpoint['epoch'] + 1}, best_val_f1: {checkpoint['best_val_f1']:.4f})\")\n",
    "\n",
    "    # Evaluate on validation set (since we don't have a separate test set)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating on validation set\"):\n",
    "            x = batch['features'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            preds = (probs > 0.5).long()  # 0.5 threshold\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "\n",
    "    print(f\"\\nüìä Validation Set Performance:\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall: {recall:.4f}\")\n",
    "    print(f\"   F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Negative', 'Wakeword'],\n",
    "                yticklabels=['Negative', 'Wakeword'])\n",
    "    plt.title('Confusion Matrix (Validation Set)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Negative', 'Wakeword']))\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No trained model found. Please run the training cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wakeword_from_features(features, model, device, threshold=0.5):\n",
    "    \"\"\"Predict if audio features contain wakeword\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Convert to tensor and add batch dimension\n",
    "    if not isinstance(features, torch.Tensor):\n",
    "        features = torch.FloatTensor(features)\n",
    "\n",
    "    # Ensure correct shape (B, C, T)\n",
    "    if features.dim() == 2:\n",
    "        features = features.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    features = features.to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        wakeword_prob = probs[0][1].item()\n",
    "\n",
    "    is_wakeword = wakeword_prob >= threshold\n",
    "    return is_wakeword, wakeword_prob\n",
    "\n",
    "# Test prediction function on test files\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    checkpoint = torch.load('best_wakeword_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    print(\"üéØ Wakeword Detection System Ready!\")\n",
    "    print(\"Testing on sample files from test_files/ directory...\")\n",
    "\n",
    "    # Test on available test files\n",
    "    test_files = ['test_files/0.wav', 'test_files/1.wav', 'test_files/2.wav', 'test_files/3.wav']\n",
    "\n",
    "    for test_file in test_files:\n",
    "        if os.path.exists(test_file):\n",
    "            try:\n",
    "                # Load and process audio file\n",
    "                audio, sr = sf.read(test_file)\n",
    "                if sr != AudioConfig.SAMPLE_RATE:\n",
    "                    # Resample if needed\n",
    "                    audio = librosa.resample(audio, orig_sr=sr, target_sr=AudioConfig.SAMPLE_RATE)\n",
    "\n",
    "                # Extract features (simple mel spectrogram)\n",
    "                mel_spec = librosa.feature.melspectrogram(\n",
    "                    y=audio,\n",
    "                    sr=AudioConfig.SAMPLE_RATE,\n",
    "                    n_mels=AudioConfig.N_MELS,\n",
    "                    n_fft=AudioConfig.N_FFT,\n",
    "                    hop_length=AudioConfig.HOP_LENGTH,\n",
    "                    fmin=AudioConfig.FMIN,\n",
    "                    fmax=AudioConfig.FMAX\n",
    "                )\n",
    "                mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "                # Normalize\n",
    "                mel_spec = (mel_spec - mel_spec.mean()) / (mel_spec.std() + 1e-8)\n",
    "\n",
    "                # Predict\n",
    "                is_wakeword, confidence = predict_wakeword_from_features(mel_spec, model, device)\n",
    "\n",
    "                print(f\"\\nüìÅ Testing: {test_file}\")\n",
    "                print(f\"   Wakeword detected: {is_wakeword}\")\n",
    "                print(f\"   Confidence: {confidence:.3f}\")\n",
    "                print(f\"   Threshold: 0.50\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing {test_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Test file not found: {test_file}\")\n",
    "else:\n",
    "    print(\"‚ùå Model not trained yet. Please run training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complete model for deployment\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    # Load the checkpoint to get training info\n",
    "    checkpoint = torch.load('best_wakeword_model.pth', map_location=device)\n",
    "\n",
    "    # Create a complete deployment package\n",
    "    deployment_package = {\n",
    "        'model_state_dict': checkpoint['model_state'],\n",
    "        'model_config': checkpoint.get('config', {\n",
    "            'HIDDEN_SIZE': ModelConfig.HIDDEN_SIZE,\n",
    "            'NUM_LAYERS': ModelConfig.NUM_LAYERS,\n",
    "            'DROPOUT': ModelConfig.DROPOUT,\n",
    "            'NUM_CLASSES': ModelConfig.NUM_CLASSES,\n",
    "            'input_size': derived_input_size\n",
    "        }),\n",
    "        'audio_config': {\n",
    "            'SAMPLE_RATE': AudioConfig.SAMPLE_RATE,\n",
    "            'DURATION': AudioConfig.DURATION,\n",
    "            'N_MELS': AudioConfig.N_MELS,\n",
    "            'N_FFT': AudioConfig.N_FFT,\n",
    "            'HOP_LENGTH': AudioConfig.HOP_LENGTH,\n",
    "            'FMIN': AudioConfig.FMIN,\n",
    "            'FMAX': AudioConfig.FMAX\n",
    "        },\n",
    "        'training_info': {\n",
    "            'best_val_f1': checkpoint.get('best_val_f1', 0),\n",
    "            'epoch': checkpoint.get('epoch', 0) + 1,\n",
    "            'device': str(device)\n",
    "        },\n",
    "        'classes': ['negative', 'wakeword']\n",
    "    }\n",
    "\n",
    "    # Save deployment package\n",
    "    torch.save(deployment_package, 'wakeword_deployment_model.pth')\n",
    "    print(\"‚úÖ Deployment model saved as 'wakeword_deployment_model.pth'\")\n",
    "\n",
    "    # Save model architecture for reference\n",
    "    with open('model_architecture.txt', 'w') as f:\n",
    "        f.write(\"Wakeword Detection Model Architecture\\n\")\n",
    "        f.write(\"================================\\n\\n\")\n",
    "        f.write(\"Model Type: CNN + LSTM with Attention\\n\")\n",
    "        f.write(f\"Input Shape: ({deployment_package['model_config']['input_size']}, T)\\n\")\n",
    "        f.write(f\"Hidden Size: {deployment_package['model_config']['HIDDEN_SIZE']}\\n\")\n",
    "        f.write(f\"Number of Layers: {deployment_package['model_config']['NUM_LAYERS']}\\n\")\n",
    "        f.write(f\"Dropout: {deployment_package['model_config']['DROPOUT']}\\n\")\n",
    "        f.write(f\"Number of Classes: {deployment_package['model_config']['NUM_CLASSES']}\\n\")\n",
    "\n",
    "        # Create a temporary model to count parameters\n",
    "        temp_model = EnhancedWakewordModel(ModelConfig())\n",
    "        temp_model.cfg = deployment_package['model_config']\n",
    "        f.write(f\"Parameters: {sum(p.numel() for p in temp_model.parameters()):,}\\n\")\n",
    "        f.write(f\"Device: {device}\\n\")\n",
    "        f.write(f\"Best Validation F1: {deployment_package['training_info']['best_val_f1']:.4f}\\n\")\n",
    "\n",
    "    print(\"‚úÖ Model architecture saved as 'model_architecture.txt'\")\n",
    "\n",
    "    print(\"\\nüéâ Model deployment package ready!\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"   - wakeword_deployment_model.pth (complete model)\")\n",
    "    print(\"   - model_architecture.txt (model specs)\")\n",
    "    print(\"   - best_wakeword_model.pth (training checkpoint)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No trained model found to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Add your wakeword recordings to positive_dataset/\")\n",
    "print(f\"   2. Add negative samples to negative_dataset/\")\n",
    "print(f\"   3. Add background noise to background_noise/\")\n",
    "print(f\"   4. Run the training cells above\")\n",
    "print(f\"   5. Use the trained model for wakeword detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
