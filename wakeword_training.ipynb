{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wakeword Detection Training System\n",
    "\n",
    "## GPU-Accelerated Wakeword Training with CNN+LSTM Architecture\n",
    "\n",
    "**System Status**: ‚úÖ GPU Ready | RTX 3060 Ti | PyTorch 2.0.1 + CUDA 11.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Setup and Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import subprocess\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU Configuration and Diagnostic\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîç System Diagnostic:\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "print(f\"   Using device: {device}\")\n",
    "print(f\"   GPU Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  GPU not detected - running on CPU\")\n",
    "    print(\"   üîß GPU Fix Suggestions:\")\n",
    "    print(\"      1. Install NVIDIA drivers: sudo apt install nvidia-driver-535\")\n",
    "    print(\"      2. Install CUDA toolkit\")\n",
    "    print(\"      3. Restart WSL: wsl --shutdown (in Windows CMD)\")\n",
    "    print(\"      4. Run: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Configuration\n",
    "class AudioConfig:\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 1.0  # seconds\n",
    "    N_MELS = 80\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    WIN_LENGTH = 2048\n",
    "    FMIN = 0\n",
    "    FMAX = 8000\n",
    "    \n",
    "# Model Configuration - Enhanced for better training\n",
    "class ModelConfig:\n",
    "    HIDDEN_SIZE = 256  # Increased capacity\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.6  # Increased dropout for regularization\n",
    "    NUM_CLASSES = 2  # wakeword vs negative\n",
    "    \n",
    "# Training Configuration - Fixed for better convergence\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE = 16  # Reduced for better gradient updates\n",
    "    LEARNING_RATE = 0.0001  # Reduced for stable training\n",
    "    EPOCHS = 50\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    TEST_SPLIT = 0.1\n",
    "    \n",
    "# Data Augmentation Configuration - Enhanced for better generalization\n",
    "class AugmentationConfig:\n",
    "    AUGMENTATION_PROB = 0.8  # Increased augmentation\n",
    "    NOISE_FACTOR = 0.15  # More noise variation\n",
    "    TIME_SHIFT_MAX = 0.3  # More time variation\n",
    "    PITCH_SHIFT_MAX = 3  # More pitch variation\n",
    "    SPEED_CHANGE_MIN = 0.7\n",
    "    SPEED_CHANGE_MAX = 1.3\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(\"üîß Enhanced configuration for better training convergence\")\n",
    "print(f\"   Learning Rate: {TrainingConfig.LEARNING_RATE}\")\n",
    "print(f\"   Batch Size: {TrainingConfig.BATCH_SIZE}\")\n",
    "print(f\"   Dropout: {ModelConfig.DROPOUT}\")\n",
    "print(f\"   Augmentation: {AugmentationConfig.AUGMENTATION_PROB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Processing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    \"\"\"Handle all audio processing tasks\"\"\"\n",
    "    \n",
    "    def __init__(self, config=AudioConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def load_audio(self, file_path):\n",
    "        \"\"\"Load audio file and return as numpy array\"\"\"\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=self.config.SAMPLE_RATE)\n",
    "            return audio\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def normalize_audio(self, audio):\n",
    "        \"\"\"Normalize audio to [-1, 1] range\"\"\"\n",
    "        if len(audio) == 0:\n",
    "            return audio\n",
    "        return audio / np.max(np.abs(audio))\n",
    "    \n",
    "    def pad_or_truncate(self, audio, target_length):\n",
    "        \"\"\"Pad or truncate audio to target length\"\"\"\n",
    "        if len(audio) > target_length:\n",
    "            # Truncate\n",
    "            start_idx = random.randint(0, len(audio) - target_length)\n",
    "            return audio[start_idx:start_idx + target_length]\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            return np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
    "    \n",
    "    def audio_to_mel(self, audio):\n",
    "        \"\"\"Convert audio to mel-spectrogram\"\"\"\n",
    "        if len(audio) == 0:\n",
    "            return np.zeros((self.config.N_MELS, int(self.config.SAMPLE_RATE * self.config.DURATION / self.config.HOP_LENGTH) + 1))\n",
    "        \n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=audio,\n",
    "            sr=self.config.SAMPLE_RATE,\n",
    "            n_mels=self.config.N_MELS,\n",
    "            n_fft=self.config.N_FFT,\n",
    "            hop_length=self.config.HOP_LENGTH,\n",
    "            win_length=self.config.WIN_LENGTH,\n",
    "            fmin=self.config.FMIN,\n",
    "            fmax=self.config.FMAX\n",
    "        )\n",
    "        \n",
    "        # Convert to log scale\n",
    "        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        return mel_spec\n",
    "    \n",
    "    def augment_audio(self, audio, config=AugmentationConfig):\n",
    "        \"\"\"Apply data augmentation to audio\"\"\"\n",
    "        augmented_audio = audio.copy()\n",
    "        \n",
    "        # Time shift\n",
    "        if random.random() < config.AUGMENTATION_PROB:\n",
    "            shift_amount = int(random.uniform(-config.TIME_SHIFT_MAX, config.TIME_SHIFT_MAX) * self.config.SAMPLE_RATE)\n",
    "            augmented_audio = np.roll(augmented_audio, shift_amount)\n",
    "        \n",
    "        # Pitch shift\n",
    "        if random.random() < config.AUGMENTATION_PROB:\n",
    "            n_steps = random.uniform(-config.PITCH_SHIFT_MAX, config.PITCH_SHIFT_MAX)\n",
    "            augmented_audio = librosa.effects.pitch_shift(y=augmented_audio, sr=self.config.SAMPLE_RATE, n_steps=n_steps)\n",
    "        \n",
    "        # Speed change\n",
    "        if random.random() < config.AUGMENTATION_PROB:\n",
    "            speed_factor = random.uniform(config.SPEED_CHANGE_MIN, config.SPEED_CHANGE_MAX)\n",
    "            augmented_audio = librosa.effects.time_stretch(y=augmented_audio, rate=speed_factor)\n",
    "            \n",
    "            # Pad or truncate to maintain original length\n",
    "            augmented_audio = self.pad_or_truncate(augmented_audio, len(audio))\n",
    "        \n",
    "        # Add background noise\n",
    "        if random.random() < config.AUGMENTATION_PROB:\n",
    "            noise = np.random.normal(0, config.NOISE_FACTOR, len(augmented_audio))\n",
    "            augmented_audio = augmented_audio + noise\n",
    "        \n",
    "        return augmented_audio\n",
    "    \n",
    "    def process_audio_file(self, file_path, augment=False):\n",
    "        \"\"\"Process a single audio file\"\"\"\n",
    "        # Load audio\n",
    "        audio = self.load_audio(file_path)\n",
    "        if audio is None:\n",
    "            return None\n",
    "        \n",
    "        # Normalize\n",
    "        audio = self.normalize_audio(audio)\n",
    "        \n",
    "        # Pad/truncate to target length\n",
    "        target_length = int(self.config.SAMPLE_RATE * self.config.DURATION)\n",
    "        audio = self.pad_or_truncate(audio, target_length)\n",
    "        \n",
    "        # Apply augmentation if requested\n",
    "        if augment:\n",
    "            audio = self.augment_audio(audio)\n",
    "        \n",
    "        # Convert to mel-spectrogram\n",
    "        mel_spec = self.audio_to_mel(audio)\n",
    "        \n",
    "        return mel_spec\n",
    "\n",
    "# Test the audio processor\n",
    "processor = AudioProcessor()\n",
    "print(\"AudioProcessor created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakewordModel(nn.Module):\n",
    "    \"\"\"CNN+LSTM model for wakeword detection\"\"\"\n",
    "    \n",
    "    def __init__(self, config=ModelConfig, audio_config=AudioConfig):\n",
    "        super(WakewordModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.audio_config = audio_config\n",
    "        \n",
    "        # Calculate CNN output size\n",
    "        self.mel_height = audio_config.N_MELS\n",
    "        self.mel_width = int(audio_config.SAMPLE_RATE * audio_config.DURATION / audio_config.HOP_LENGTH) + 1\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Calculate CNN output size\n",
    "        self.cnn_output_size = 128  # After adaptive pooling\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.cnn_output_size,\n",
    "            hidden_size=config.HIDDEN_SIZE,\n",
    "            num_layers=config.NUM_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=config.DROPOUT if config.NUM_LAYERS > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.fc = nn.Linear(config.HIDDEN_SIZE, config.NUM_CLASSES)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch, 1, mel_height, mel_width)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        x = x.view(batch_size, -1)  # (batch, cnn_output_size)\n",
    "        \n",
    "        # Add sequence dimension\n",
    "        x = x.unsqueeze(1)  # (batch, seq_len=1, features)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Take the last output\n",
    "        x = lstm_out[:, -1, :]  # (batch, hidden_size)\n",
    "        \n",
    "        # Dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final classification\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model and move to device\n",
    "model = WakewordModel().to(device)\n",
    "print(f\"Model created and moved to {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test model with dummy input\n",
    "dummy_input = torch.randn(1, 1, AudioConfig.N_MELS, 31).to(device)  # (batch, channels, height, width)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "print(f\"Dummy output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakewordDataset(Dataset):\n",
    "    \"\"\"Dataset class for wakeword detection\"\"\"\n",
    "    \n",
    "    def __init__(self, wakeword_files, negative_files, processor, augment=False):\n",
    "        self.wakeword_files = wakeword_files\n",
    "        self.negative_files = negative_files\n",
    "        self.processor = processor\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Combine files and create labels\n",
    "        self.files = wakeword_files + negative_files\n",
    "        self.labels = [1] * len(wakeword_files) + [0] * len(negative_files)\n",
    "        \n",
    "        print(f\"Dataset created with {len(self.files)} samples\")\n",
    "        print(f\"Wakeword samples: {len(wakeword_files)}\")\n",
    "        print(f\"Negative samples: {len(negative_files)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Process audio file\n",
    "        mel_spec = self.processor.process_audio_file(file_path, augment=self.augment)\n",
    "        \n",
    "        if mel_spec is None:\n",
    "            # Return zeros if processing failed\n",
    "            mel_spec = np.zeros((self.processor.config.N_MELS, 31))\n",
    "        \n",
    "        # Convert to tensor\n",
    "        mel_tensor = torch.FloatTensor(mel_spec).unsqueeze(0)  # Add channel dimension\n",
    "        label_tensor = torch.LongTensor([label])\n",
    "        \n",
    "        return mel_tensor, label_tensor\n",
    "\n",
    "# Placeholder for dataset creation\n",
    "print(\"Dataset class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakewordTrainer:\n",
    "    \"\"\"Enhanced training class with learning rate scheduling\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device, config=TrainingConfig):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='max', factor=0.5, patience=5\n",
    "        )\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "        # Early stopping\n",
    "        self.patience = 10\n",
    "        self.best_val_acc = 0.0\n",
    "        self.epochs_no_improve = 0\n",
    "        \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train for one epoch with gradient clipping\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "            data, target = data.to(self.device), target.to(self.device).squeeze()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(val_loader, desc=\"Validating\"):\n",
    "                data, target = data.to(self.device), target.to(self.device).squeeze()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs):\n",
    "        \"\"\"Complete training loop with early stopping\"\"\"\n",
    "        print(f\"Starting training for {epochs} epochs...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        print(f\"Learning rate: {self.config.LEARNING_RATE}\")\n",
    "        print(f\"Batch size: {self.config.BATCH_SIZE}\")\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.epochs_no_improve = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            # GPU Memory monitoring\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_memory = torch.cuda.memory_allocated() / 1e6\n",
    "                gpu_reserved = torch.cuda.memory_reserved() / 1e6\n",
    "                print(f\"GPU Memory: {gpu_memory:.1f}MB allocated, {gpu_reserved:.1f}MB reserved\")\n",
    "            else:\n",
    "                print(\"GPU Memory: Not available (using CPU)\")\n",
    "            \n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc = self.validate(val_loader)\n",
    "            \n",
    "            # Store metrics\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.train_accuracies.append(train_acc)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_acc)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.epochs_no_improve = 0\n",
    "                \n",
    "                # Save best model\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'train_acc': train_acc,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                }, 'best_wakeword_model.pth')\n",
    "                print(f\"üéâ New best model saved! Validation accuracy: {val_acc:.2f}%\")\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "                \n",
    "            # Early stopping\n",
    "            if self.epochs_no_improve >= self.patience:\n",
    "                print(f\"\\n‚èπÔ∏è  Early stopping triggered! No improvement for {self.patience} epochs.\")\n",
    "                print(f\"Best validation accuracy: {self.best_val_acc:.2f}%\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nüéâ Training completed!\")\n",
    "        print(f\"Best validation accuracy: {self.best_val_acc:.2f}%\")\n",
    "        print(f\"Total epochs trained: {epoch + 1}\")\n",
    "        return self.best_val_acc\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(self.train_losses, label='Train Loss', linewidth=2)\n",
    "        ax1.plot(self.val_losses, label='Val Loss', linewidth=2)\n",
    "        ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax2.plot(self.train_accuracies, label='Train Accuracy', linewidth=2)\n",
    "        ax2.plot(self.val_accuracies, label='Val Accuracy', linewidth=2)\n",
    "        ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create trainer instance\n",
    "trainer = WakewordTrainer(model, device)\n",
    "print(\"Enhanced trainer created successfully!\")\n",
    "print(\"üîß Added: Learning rate scheduling, gradient clipping, early stopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "# Check if data directories exist\n",
    "data_dirs = ['wakeword_data', 'negative_data', 'background_noise']\n",
    "missing_dirs = []\n",
    "\n",
    "for dir_name in data_dirs:\n",
    "    if not os.path.exists(dir_name):\n",
    "        missing_dirs.append(dir_name)\n",
    "    \n",
    "if missing_dirs:\n",
    "    print(\"‚ö†Ô∏è  Missing data directories:\")\n",
    "    for dir_name in missing_dirs:\n",
    "        print(f\"   - {dir_name}/\")\n",
    "    print(\"\\nPlease create these directories and add your audio files:\")\n",
    "    print(\"   - wakeword_data/ : Your 500+ wakeword recordings\")\n",
    "    print(\"   - negative_data/ : Thousands of negative audio samples\")\n",
    "    print(\"   - background_noise/ : 100+ hours of background noise\")\n",
    "    \n",
    "    # Create directories\n",
    "    for dir_name in missing_dirs:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        print(f\"‚úÖ Created directory: {dir_name}/\")\n",
    "else:\n",
    "    print(\"‚úÖ All data directories found!\")\n",
    "\n",
    "# Load audio files (recursive)\n",
    "def load_audio_files(directory, extensions=None):\n",
    "    \"\"\"Return a list of audio file paths under directory and all subfolders.\"\"\"\n",
    "    if extensions is None:\n",
    "        extensions = ['*.wav', '*.mp3', '*.flac', '*.m4a', '*.ogg', '*.opus']\n",
    "    files = []\n",
    "    for ext in extensions:\n",
    "        # ** makes it recursive\n",
    "        pattern = os.path.join(directory, '**', ext)\n",
    "        files.extend(glob.glob(pattern, recursive=True))\n",
    "    return files\n",
    "\n",
    "wakeword_files = load_audio_files('wakeword_data')\n",
    "negative_files = load_audio_files('negative_data')\n",
    "background_files = load_audio_files('background_noise')\n",
    "\n",
    "print(f\"\\nüìä Data Summary (recursive):\")\n",
    "print(f\"   Wakeword files: {len(wakeword_files)}\")\n",
    "print(f\"   Negative files: {len(negative_files)}\")\n",
    "print(f\"   Background noise files: {len(background_files)}\")\n",
    "\n",
    "if len(wakeword_files) == 0 or len(negative_files) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Not enough data files found!\")\n",
    "    print(\"Please add audio files to the respective directories before training.\")\n",
    "else:\n",
    "    print(\"‚úÖ Data files loaded successfully!\")\n",
    "    \n",
    "    # Split data for training\n",
    "    from sklearn.model_selection import train_test_split  # ensure import exists\n",
    "\n",
    "    wakeword_train, wakeword_test = train_test_split(\n",
    "        wakeword_files, test_size=TrainingConfig.TEST_SPLIT, random_state=42\n",
    "    )\n",
    "    wakeword_train, wakeword_val = train_test_split(\n",
    "        wakeword_train, test_size=TrainingConfig.VALIDATION_SPLIT, random_state=42\n",
    "    )\n",
    "    \n",
    "    negative_train, negative_test = train_test_split(\n",
    "        negative_files, test_size=TrainingConfig.TEST_SPLIT, random_state=42\n",
    "    )\n",
    "    negative_train, negative_val = train_test_split(\n",
    "        negative_train, test_size=TrainingConfig.VALIDATION_SPLIT, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìà Data Split:\")\n",
    "    print(f\"   Training: {len(wakeword_train)} wakeword + {len(negative_train)} negative = {len(wakeword_train) + len(negative_train)} total\")\n",
    "    print(f\"   Validation: {len(wakeword_val)} wakeword + {len(negative_val)} negative = {len(wakeword_val) + len(negative_val)} total\")\n",
    "    print(f\"   Test: {len(wakeword_test)} wakeword + {len(negative_test)} negative = {len(wakeword_test) + len(negative_test)} total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have enough data for training\n",
    "if len(wakeword_files) > 0 and len(negative_files) > 0:\n",
    "    # Create datasets\n",
    "    train_dataset = WakewordDataset(wakeword_train, negative_train, processor, augment=True)\n",
    "    val_dataset = WakewordDataset(wakeword_val, negative_val, processor, augment=False)\n",
    "    test_dataset = WakewordDataset(wakeword_test, negative_test, processor, augment=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=TrainingConfig.BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=TrainingConfig.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=TrainingConfig.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting Training...\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(f\"   Batch size: {TrainingConfig.BATCH_SIZE}\")\n",
    "    print(f\"   Learning rate: {TrainingConfig.LEARNING_RATE}\")\n",
    "    print(f\"   Epochs: {TrainingConfig.EPOCHS}\")\n",
    "    print(f\"   Training samples: {len(train_dataset)}\")\n",
    "    print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Train the model\n",
    "    try:\n",
    "        best_val_acc = trainer.train(train_loader, val_loader, TrainingConfig.EPOCHS)\n",
    "        \n",
    "        # Plot training history\n",
    "        trainer.plot_training_history()\n",
    "        \n",
    "        print(f\"\\nüéâ Training completed successfully!\")\n",
    "        print(f\"   Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during training: {e}\")\n",
    "        print(\"Please check your data files and try again.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot start training - missing data files!\")\n",
    "    print(\"Please add audio files to wakeword_data/ and negative_data/ directories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best model loaded (epoch 42, val_acc: 98.93%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:03<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 0.9826\n",
      "   Precision: 0.9827\n",
      "   Recall: 0.9826\n",
      "   F1-Score: 0.9827\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.99      0.99      0.99      1141\n",
      "    Wakeword       0.97      0.98      0.97       529\n",
      "\n",
      "    accuracy                           0.98      1670\n",
      "   macro avg       0.98      0.98      0.98      1670\n",
      "weighted avg       0.98      0.98      0.98      1670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best model for evaluation\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    checkpoint = torch.load('best_wakeword_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úÖ Best model loaded (epoch {checkpoint['epoch'] + 1}, val_acc: {checkpoint['val_acc']:.2f}%)\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device).squeeze()\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f\"\\nüìä Test Set Performance:\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall: {recall:.4f}\")\n",
    "    print(f\"   F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Negative', 'Wakeword'], \n",
    "                yticklabels=['Negative', 'Wakeword'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Negative', 'Wakeword']))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No trained model found. Please run the training cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Wakeword Detection System Ready!\n",
      "You can now use the predict_wakeword function for real-time detection.\n",
      "\n",
      "Example usage:\n",
      "is_wakeword, confidence = predict_wakeword('./test_files/3.wav', model, processor, device)\n",
      "Result: {'wakeword_detected': is_wakeword, 'confidence': confidence:.2f}\n",
      "\n",
      "üìÅ Testing: ./test_files/3.wav\n",
      "   Wakeword detected: True\n",
      "   Confidence: 0.88\n",
      "   Threshold: 0.80\n"
     ]
    }
   ],
   "source": [
    "def predict_wakeword(audio_file_path, model, processor, device, threshold=0.8):\n",
    "    \"\"\"Predict if audio contains wakeword\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Process audio file\n",
    "    mel_spec = processor.process_audio_file(audio_file_path, augment=False)\n",
    "    \n",
    "    if mel_spec is None:\n",
    "        print(f\"Error processing audio file: {audio_file_path}\")\n",
    "        return False, 0.0\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    mel_tensor = torch.FloatTensor(mel_spec).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(mel_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        wakeword_prob = probabilities[0][1].item()\n",
    "        \n",
    "    is_wakeword = wakeword_prob >= threshold\n",
    "    \n",
    "    return is_wakeword, wakeword_prob\n",
    "\n",
    "# Test prediction function\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    print(\"\\nüéØ Wakeword Detection System Ready!\")\n",
    "    print(\"You can now use the predict_wakeword function for real-time detection.\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"is_wakeword, confidence = predict_wakeword('./test_files/3.wav', model, processor, device)\")\n",
    "    print(f\"Result: {{'wakeword_detected': is_wakeword, 'confidence': confidence:.2f}}\")\n",
    "    \n",
    "    # Create a simple test function\n",
    "    def test_audio_file(file_path):\n",
    "        if os.path.exists(file_path):\n",
    "            is_wakeword, confidence = predict_wakeword(file_path, model, processor, device)\n",
    "            print(f\"\\nüìÅ Testing: {file_path}\")\n",
    "            print(f\"   Wakeword detected: {is_wakeword}\")\n",
    "            print(f\"   Confidence: {confidence:.2f}\")\n",
    "            print(f\"   Threshold: 0.80\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå File not found: {file_path}\")\n",
    "    \n",
    "    # Direct test with ./test_files/1.wav\n",
    "    test_audio_file(\"./test_files/3.wav\")\n",
    "else:\n",
    "    print(\"‚ùå Model not trained yet. Please run training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deployment model saved as 'wakeword_deployment_model.pth'\n",
      "‚úÖ Model architecture saved as 'model_architecture.txt'\n",
      "\n",
      "üéâ Model deployment package ready!\n",
      "Files created:\n",
      "   - wakeword_deployment_model.pth (complete model)\n",
      "   - model_architecture.txt (model specs)\n",
      "   - best_wakeword_model.pth (training checkpoint)\n"
     ]
    }
   ],
   "source": [
    "# Save the complete model for deployment\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    # Create a complete deployment package\n",
    "    deployment_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_config': {\n",
    "            'HIDDEN_SIZE': ModelConfig.HIDDEN_SIZE,\n",
    "            'NUM_LAYERS': ModelConfig.NUM_LAYERS,\n",
    "            'DROPOUT': ModelConfig.DROPOUT,\n",
    "            'NUM_CLASSES': ModelConfig.NUM_CLASSES\n",
    "        },\n",
    "        'audio_config': {\n",
    "            'SAMPLE_RATE': AudioConfig.SAMPLE_RATE,\n",
    "            'DURATION': AudioConfig.DURATION,\n",
    "            'N_MELS': AudioConfig.N_MELS,\n",
    "            'N_FFT': AudioConfig.N_FFT,\n",
    "            'HOP_LENGTH': AudioConfig.HOP_LENGTH,\n",
    "            'FMIN': AudioConfig.FMIN,\n",
    "            'FMAX': AudioConfig.FMAX\n",
    "        },\n",
    "        'training_info': {\n",
    "            'best_val_accuracy': checkpoint.get('val_acc', 0),\n",
    "            'epoch': checkpoint.get('epoch', 0) + 1,\n",
    "            'device': str(device)\n",
    "        },\n",
    "        'classes': ['negative', 'wakeword']\n",
    "    }\n",
    "    \n",
    "    # Save deployment package\n",
    "    torch.save(deployment_package, 'wakeword_deployment_model.pth')\n",
    "    print(\"‚úÖ Deployment model saved as 'wakeword_deployment_model.pth'\")\n",
    "    \n",
    "    # Save model architecture for reference\n",
    "    with open('model_architecture.txt', 'w') as f:\n",
    "        f.write(\"Wakeword Detection Model Architecture\\n\")\n",
    "        f.write(\"================================\\n\\n\")\n",
    "        f.write(\"Model Type: CNN + LSTM\\n\")\n",
    "        f.write(f\"Input Shape: (1, {AudioConfig.N_MELS}, 31)\\n\")\n",
    "        f.write(f\"Hidden Size: {ModelConfig.HIDDEN_SIZE}\\n\")\n",
    "        f.write(f\"Number of Layers: {ModelConfig.NUM_LAYERS}\\n\")\n",
    "        f.write(f\"Dropout: {ModelConfig.DROPOUT}\\n\")\n",
    "        f.write(f\"Number of Classes: {ModelConfig.NUM_CLASSES}\\n\")\n",
    "        f.write(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
    "        f.write(f\"Device: {device}\\n\")\n",
    "    \n",
    "    print(\"‚úÖ Model architecture saved as 'model_architecture.txt'\")\n",
    "    \n",
    "    print(\"\\nüéâ Model deployment package ready!\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"   - wakeword_deployment_model.pth (complete model)\")\n",
    "    print(\"   - model_architecture.txt (model specs)\")\n",
    "    print(\"   - best_wakeword_model.pth (training checkpoint)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No trained model found to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Wakeword Training System Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nüìä System Status:\")\n",
    "print(f\"   GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"   PyTorch Version: {torch.__version__}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "print(f\"\\nüìÅ Data Status:\")\n",
    "print(f\"   Wakeword files: {len(wakeword_files)}\")\n",
    "print(f\"   Negative files: {len(negative_files)}\")\n",
    "print(f\"   Data directories created: {len([d for d in data_dirs if os.path.exists(d)])}/3\")\n",
    "\n",
    "print(f\"\\nüß† Model Status:\")\n",
    "print(f\"   Model created: {model is not None}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Model on device: {next(model.parameters()).device}\")\n",
    "\n",
    "if os.path.exists('best_wakeword_model.pth'):\n",
    "    print(f\"\\n‚úÖ Training Status: Completed\")\n",
    "    print(f\"   Model saved: best_wakeword_model.pth\")\n",
    "    print(f\"   Deployment model: wakeword_deployment_model.pth\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Training Status: Not started or incomplete\")\n",
    "    print(f\"   Ready to train when data is available\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Add your wakeword recordings to wakeword_data/\")\n",
    "print(f\"   2. Add negative samples to negative_data/\")\n",
    "print(f\"   3. Add background noise to background_noise/\")\n",
    "print(f\"   4. Run the training cells above\")\n",
    "print(f\"   5. Use the trained model for wakeword detection\")\n",
    "\n",
    "print(f\"\\nüí° Tips:\")\n",
    "print(f\"   - Use at least 100 wakeword recordings for good results\")\n",
    "print(f\"   - More negative samples improve false positive reduction\")\n",
    "print(f\"   - Background noise helps with robustness\")\n",
    "print(f\"   - Monitor GPU memory usage during training\")\n",
    "print(f\"   - Adjust hyperparameters based on your dataset size\")\n",
    "\n",
    "print(f\"\\nüéâ System ready for wakeword training with GPU acceleration!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
